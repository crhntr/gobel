package ecgo

import (
	"fmt"
	"sort"
	"strings"
	"unicode"
	"unicode/utf8"
)

type tokenType int

// Token is a unit generated by the lexer whitch includes a type
// or value
type Token struct {
	Type  tokenType
	Value string
}

func (tok Token) String() string {
	val, tokTypStr := "", ""
	var ok bool
	if tokTypStr, ok = tokenTypeStrings[tok.Type]; !ok {
		tokTypStr = "UNKOWN_TOKEN_TYPE"
	}
	if len(tok.Value) > 0 {
		val = " \"" + tok.Value + "\""
	}
	return fmt.Sprintf("<%s%s>", tokTypStr, val)
}

func (tok Token) equals(otherTok Token) bool {
	/*  ||
	!((tok.Err == nil) || (otherTok.Err == nil)) ||
	tok.Err.Error() == otherTok.Err.Error()
	*/
	return tok.Type == otherTok.Type &&
		tok.Value == otherTok.Value
}

const eof rune = -1

/*
// not handled TokenTypes
// TODO missing LineTerminatorSequence
*/
const (
	Error tokenType = iota
	EOF
	// Comment ::
	MultiLineComment
	SingleLineComment
	// WhiteSpace ::
	WhiteSpace
	// LineTerminator ::
	LineTerminator
	// ComomonToken ::
	IdentifierName
	ReservedWord
	//   Punctuator
	Punctuator
	RightBracePunctuator
	DivPunctuator

	NumericLiteral
	StringLiteral
	Template
)

var tokenTypeStrings = map[tokenType]string{
	Error:                "Error",
	EOF:                  "EOF",
	MultiLineComment:     "MultiLineComment",
	SingleLineComment:    "SingleLineComment",
	WhiteSpace:           "WhiteSpace",
	LineTerminator:       "LineTerminator",
	IdentifierName:       "IdentifierName",
	ReservedWord:         "ReservedWord",
	Punctuator:           "Punctuator",
	RightBracePunctuator: "RightBracePunctuator",
	DivPunctuator:        "DivPunctuator",
	NumericLiteral:       "NumericLiteral",
	StringLiteral:        "StringLiteral",
	Template:             "Template",
}

type lexer struct {
	name          string     // used for error reports
	input         string     // the string being scanned
	start         int        // start position of this item
	pos           int        // current position of this input
	width         int        // width of last rune read
	tokens        chan Token // channel if scanned tokens
	reservedWords []string
	strict        bool
	flags         struct {
		div          bool
		regExp       bool
		templateTail bool
	}
}

// func (l lexer) String() string {
// 	return fmt.Sprintf("name: \"%s\", start: %d, pos: %d, width: %d, input: \n------\n%s\n-----,",
// 		l.name, l.start, l.pos, l.width, l.input)
// }

// copied from: https://gobyexample.com/sorting-by-functions
type keywordSorter []string

func (s keywordSorter) Len() int {
	return len(s)
}
func (s keywordSorter) Swap(i, j int) {
	s[i], s[j] = s[j], s[i]
}
func (s keywordSorter) Less(i, j int) bool {
	return len(s[i]) > len(s[j]) // sorts reverse order
}

func (l *lexer) setStrict() {
	l.strict = true
	l.reservedWords = []string{}
	l.reservedWords = append(currentReservedWords, futureReservedWords...)
	l.reservedWords = append(currentReservedWords, literals...)
	l.reservedWords = append(l.reservedWords, futureResdervedWordsStrict...)
	sort.Sort(keywordSorter(l.reservedWords))
}

func (l *lexer) unsetStrict() {
	l.strict = false
	l.reservedWords = []string{}
	l.reservedWords = append(currentReservedWords, futureReservedWords...)
	l.reservedWords = append(currentReservedWords, literals...)
	sort.Sort(keywordSorter(l.reservedWords))
}

type stateFunc func(*lexer) stateFunc

// state may be used in refactor to improve
// switch logic
// type state interface {
// 	lex(*lexer) stateFunc
// 	canBeNext(string) bool
// }

func lex(name, input string, safe bool) (*lexer, chan Token) {
	l := &lexer{
		name:   name,
		input:  input,
		tokens: make(chan Token),
		strict: true,
	}
	l.flags.div = true
	if safe {
		l.setStrict()
	} else {
		l.unsetStrict()
	}

	go l.run()
	return l, l.tokens
}

// run lexes the input by executing state functions
// until the state is nil
func (l *lexer) run() {
	for state := lexInputElement; state != nil; {
		state = state(l)
	}
	close(l.tokens)
}

// emit passes an item back to the client.
func (l *lexer) emit(tok tokenType) {
	l.tokens <- Token{tok, l.input[l.start:l.pos]}
	l.start = l.pos
}

func (l *lexer) next() (r rune) {
	if l.pos >= len(l.input) {
		l.width = 0
		return eof
	}
	r, l.width = utf8.DecodeRuneInString(l.input[l.pos:])
	l.pos += l.width
	return r

}

func (l *lexer) nextN(n int) string {
	str := ""
	for i := 0; i < n; i++ {
		str += string(l.next())
	}
	return str
}

// peek returns but does not consume the next
// next rune in the input
func (l *lexer) peek() rune {
	r := l.next()
	l.backup()
	return r
}

// accept consumes the next rune if it is from
// a valid set
func (l *lexer) accept(validSet string) bool {
	if strings.IndexRune(validSet, l.next()) >= 0 {
		return true
	}
	l.backup()
	return false
}

// acceptRun consumes a run of runes from the
// valid set
func (l *lexer) acceptRun(validSet string) {
	for strings.IndexRune(validSet, l.next()) >= 0 {
	}
	l.backup()
}

// acceptString consumes a string
func (l *lexer) acceptString(str string) bool {
	if strings.HasPrefix(l.input[l.pos:], str) {
		for _, r := range str {
			l.accept(string(r))
		}
		return true
	}
	return false
}

// acceptAnyString consumes any one of a slice of strings
func (l *lexer) acceptAnyString(valids []string) bool {
	for _, valid := range valids {
		if l.acceptString(valid) {
			return true
		}
	}
	return false
}

// accepted
func (l *lexer) accepted() bool {
	return l.pos > l.start
}

// ignore steps over the pending input before
// this point.
func (l *lexer) ignore() {
	l.start = l.pos
}

// reset
func (l *lexer) reset() {
	l.pos = l.start
}

// backup steps back once per rune
// Can be called once per call of next
func (l *lexer) backup() {
	l.pos -= l.width
}

// error returns an error token and terminates the scan
// by passing back a nil pointer that will be the next
// state, terminating l.run.
func (l *lexer) errorf(format string, args ...interface{}) stateFunc {
	l.tokens <- Token{
		Error,
		fmt.Sprintf(format, args...),
	}
	return nil
}

// lexInputElement multiplexes the various states based on
// input prefix checks. it follows the following rules from
// the specification when determinint what states are allowed
//
// InputElementDiv :: WhiteSpace | LineTerminator | Comment | CommonToken | DivPunctuator | RightBracePunctuator
// InputElementRegExp :: WhiteSpace | LineTerminator | Comment | CommonToken | RightBracePunctuator | RegularExpressionLiteral
// InputElementRegExpOrTemplateTail :: WhiteSpace | LineTerminator | Comment | CommonToken | RegularExpressionLiteral | TemplateSubstitutionTail
// InputElementTemplateTail :: | WhiteSpace | LineTerminator | Comment | CommonToken | DivPunctuator | TemplateSubstitutionTail
func lexInputElement(l *lexer) stateFunc {
	switch {
	case hasWhiteSpacePrefix(l.input[l.pos:]):
		return lexWhiteSpace
	case hasLineTerminatorPrefix(l.input[l.pos:]):
		return lexLineTerminator
	case strings.HasPrefix(l.input[l.pos:], "//"): // SingleLineComment
		return lexSingleLineComment
	case strings.HasPrefix(l.input[l.pos:], "/*"): // MultiLineComment
		return lexMultiLineComment
	case hasReservedWord(l, l.input[l.pos:]):
		return lexReservedWord(l)
	case hasNumericLiteral(l):
		return lexNumericLiteral(l)
	case hasPunctuator(l):
		return lexPunctuator(l)
	case hasIdentifierNameStartPrefix(l): // IdentifierName
		return lexIdentifierName(l)
	case strings.HasPrefix(l.input[l.pos:], "\""): // StringLiteral
		return lexStringLiteralDouble(l)
	case strings.HasPrefix(l.input[l.pos:], "'"): // StringLiteral
		return lexStringLiteralSingle(l)
	case l.flags.div && hasDivPunctuator(l): // DivPunctuator
		return lexDivPunctuator(l)
	case !l.flags.templateTail && strings.HasPrefix(l.input[l.pos:], "}"): // RightBracePunctuator
		return lexRightBracePunctuator(l)
	}
	return nil
}

// func f(l *lexer) (stateFunc, bool) {
// 	return nil, false
// }

var punctuators = []string{
	"{", "(", ")",
	">>>=", "<<=", "!==", "===", ">>>", "...", ">>=", ">=",
	"%=", "*=", "-=", "<=", "&=", "==", "!=", "|=",
	"^=", "+=", "<<", "||", "&&", "++", "--", "=>",
	">>", "-", "&", "|", "^", "!", "~", "%",
	"*", "?", ":", "=", "+", ">", "<", ",",
	";", ".", "]", "["}

func hasPunctuator(l *lexer) bool {
	defer l.reset()
	return l.acceptAnyString(punctuators)
}

func lexPunctuator(l *lexer) stateFunc {
	l.acceptAnyString(punctuators)
	l.emit(Punctuator)
	return lexInputElement
}

func hasDivPunctuator(l *lexer) bool {
	defer l.reset()
	return l.acceptAnyString([]string{"/=", "/"})
}

func lexDivPunctuator(l *lexer) stateFunc {
	l.acceptAnyString([]string{"/=", "/"})
	l.emit(DivPunctuator)
	return lexInputElement
	// }
}

func lexRightBracePunctuator(l *lexer) stateFunc {
	// if strings.HasPrefix(l.input[l.pos:], "}") {
	l.accept("}")
	l.emit(RightBracePunctuator)
	return lexInputElement
	// }
	// return l.error(fmt.Errorf("div punctuator not found")) // Paranoic (should never happen)
}

var currentReservedWords = []string{
	"break", "do", "instanceof", "in",
	"typeof", "case", "else", "var",
	"catch", "export", "new", "void",
	"class", "extends", "return", "while",
	"const", "finally", "super", "with",
	"continue", "for", "switch", "yield",
	"debugger", "function", "this", "default",
	"if", "throw", "delete", "import", "try"}
var futureReservedWords = []string{"enum", "await"}
var futureResdervedWordsStrict = []string{"implements", "package", "protected", "interface", "private", "public"}
var literals = []string{"null", "true", "false"}

func hasReservedWord(l *lexer, str string) bool {
	for _, word := range l.reservedWords {
		if strings.HasPrefix(str, word) {
			return true
		}
	}
	return false
}

func lexReservedWord(l *lexer) stateFunc {
	l.acceptAnyString(l.reservedWords)
	l.emit(ReservedWord)
	return lexInputElement
}

func hasWhiteSpacePrefix(str string) bool {
	return strings.HasPrefix(str, string('\u0009')) || // WhiteSpace
		strings.HasPrefix(str, string('\u000B')) ||
		strings.HasPrefix(str, string('\u000C')) ||
		strings.HasPrefix(str, string('\u0020')) ||
		strings.HasPrefix(str, string('\u00A0')) ||
		strings.HasPrefix(str, string('\uFEFF')) ||
		strings.HasPrefix(str, string('\uFEFF'))
}

func lexWhiteSpace(l *lexer) stateFunc {
	l.acceptRun("\u0009\u000B\u000C\u0020\u00A0\uFEFF\uFEFF")
	l.emit(WhiteSpace)
	return lexInputElement
}

func hasLineTerminatorPrefix(str string) bool {
	return strings.HasPrefix(str, string('\u000A')) || // WhiteSpace
		strings.HasPrefix(str, string('\u000D')) ||
		strings.HasPrefix(str, string('\u2028')) ||
		strings.HasPrefix(str, string('\u2029'))
}

func lexLineTerminator(l *lexer) stateFunc {
	l.next()
	l.emit(LineTerminator)
	return lexInputElement
}

func lexMultiLineComment(l *lexer) stateFunc {
	l.acceptString("/*")
	l.ignore()
	var r rune
	for {
		if strings.HasPrefix(l.input[l.pos:], "*/") {
			if l.pos > l.start {
				l.emit(MultiLineComment)
			}
			l.nextN(2) // */
			l.ignore()
			return lexInputElement
		}
		if r = l.next(); r == eof {
			break
		}
	}
	return l.errorf("no multi line comment terminator \"*/\"")
}

func lexSingleLineComment(l *lexer) stateFunc {
	l.acceptString("//")
	l.ignore()
	for {
		if strings.HasPrefix(l.input[l.pos:], "\n") || l.next() == eof {
			l.emit(SingleLineComment)
			l.accept("\n")
			l.ignore()
			return lexInputElement
		}
	}
}

func hasIdentifierNameStartPrefix(l *lexer) bool {
	r := l.peek()
	return r == '$' || r == '_' ||
		(unicode.IsOneOf([]*unicode.RangeTable{unicode.L, unicode.Nd, unicode.Other_ID_Start}, r) &&
			!(unicode.IsOneOf([]*unicode.RangeTable{unicode.Pattern_Syntax, unicode.Pattern_White_Space}, r)))
}

func hasIdentifierNameContinuePrefix(l *lexer) bool {
	r := l.peek()
	return hasIdentifierNameStartPrefix(l) || unicode.IsOneOf([]*unicode.RangeTable{unicode.L, unicode.Mn, unicode.Mc, unicode.Nd, unicode.Pc, unicode.Other_ID_Start}, r)
}

func lexIdentifierName(l *lexer) stateFunc {
	l.next()
	for {
		if !hasIdentifierNameContinuePrefix(l) {
			l.emit(IdentifierName)
			return lexInputElement
		}
		l.next()
	}
}

// lexStringLiteralDouble consumes a string literal surounded by
// a double quotation marks
func lexStringLiteralDouble(l *lexer) stateFunc {
	l.accept("\"")
	var r rune
	for {
		if strings.HasPrefix(l.input[l.pos:], "\"") {
			break
		}
		if r = l.next(); r == eof {
			l.errorf("did not reach end of string literal reached eof")
			break
		}
	}
	l.accept("\"")
	l.emit(StringLiteral)
	return lexInputElement
}

// lexStringLiteralSingle consumes a string literal surounded by
// a single quotation marks
func lexStringLiteralSingle(l *lexer) stateFunc {
	l.accept("'")
	var r rune
	for {
		if strings.HasPrefix(l.input[l.pos:], "'") {
			break
		}
		if r = l.next(); r == eof {
			l.errorf("did not reach end of string literal reached eof")
			break
		}
	}
	l.accept("'")
	l.emit(StringLiteral)
	return lexInputElement
}

func hasNumericLiteral(l *lexer) bool {
	defer l.reset()
	l.accept("-")
	return l.accept("123456789") || (l.accept(".") && l.accept("0123456789")) || (l.accept("0") && (l.accept("oOxXbB") || !hasIdentifierNameStartPrefix(l)))
}

// lexNumericLiteral inspired by Rob Pike's talk
func lexNumericLiteral(l *lexer) stateFunc {
	const decDigits = "0123456789"
	// Optional leading sign.
	l.accept("-")
	// Is it hex?
	if l.accept("0") {
		if l.accept("xX") {
			l.acceptRun("0123456789abcdefABCDEF")
			l.emit(NumericLiteral)
			return lexInputElement
		} else if l.accept("oO") { // Is it octal?
			l.acceptRun("01234567")
			l.emit(NumericLiteral)
			return lexInputElement
		} else if l.accept("bB") { // Is it bin?
			l.acceptRun("01")
			l.emit(NumericLiteral)
			return lexInputElement
		}
	}

	if l.accept("123456789") {
		l.acceptRun(decDigits)
	}

	if l.accept(".") {
		l.acceptRun(decDigits)
	}

	if l.accepted() && l.accept("eE") {
		l.accept("+-")
		l.acceptRun(decDigits)
	}

	// Next thing mustn't be alphanumeric.
	if unicode.IsLetter(l.peek()) {
		l.next()
		return l.errorf("bad number syntax: %q",
			l.input[l.start:l.pos])
	}
	l.emit(NumericLiteral)
	return lexInputElement
}
