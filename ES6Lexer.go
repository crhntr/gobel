package ecgo

import (
	"fmt"
	"sort"
	"strings"
	"unicode"
	"unicode/utf8"
)

type tokenType int

// Token is a unit generated by the lexer whitch includes a type
// or value
type Token struct {
	Type  tokenType
	Value string
	Err   error
}

func (tok Token) String() string {
	val, tokTypStr := "", ""
	var ok bool
	if tokTypStr, ok = tokenTypeStrings[tok.Type]; !ok {
		tokTypStr = "UNKOWN_TOKEN_TYPE"
	}
	if len(tok.Value) > 0 {
		val = " \"" + tok.Value + "\""
	}
	return fmt.Sprintf("<%s%s>", tokTypStr, val)
}

func (tok Token) equals(otherTok Token) bool {
	/*  ||
	!((tok.Err == nil) || (otherTok.Err == nil)) ||
	tok.Err.Error() == otherTok.Err.Error()
	*/
	return tok.Type == otherTok.Type &&
		tok.Value == otherTok.Value &&
		((tok.Err == nil) == (otherTok.Err == nil))
}

const eof rune = -1

/*
// not handled TokenTypes
// TODO missing LineTerminatorSequence
*/
const (
	Error tokenType = iota
	EOF
	// Comment ::
	MultiLineComment
	SingleLineComment
	// WhiteSpace ::
	WhiteSpace
	// LineTerminator ::
	LineTerminator
	// ComomonToken ::
	IdentifierName
	ReservedWord
	//   Punctuator
	Punctuator
	RightBracePunctuator
	DivPunctuator

	NumericLiteral
	StringLiteral
	Template
)

var tokenTypeStrings = map[tokenType]string{
	Error:                "Error",
	EOF:                  "EOF",
	MultiLineComment:     "MultiLineComment",
	SingleLineComment:    "SingleLineComment",
	WhiteSpace:           "WhiteSpace",
	LineTerminator:       "LineTerminator",
	IdentifierName:       "IdentifierName",
	ReservedWord:         "ReservedWord",
	Punctuator:           "Punctuator",
	RightBracePunctuator: "RightBracePunctuator",
	DivPunctuator:        "DivPunctuator",
	NumericLiteral:       "NumericLiteral",
	StringLiteral:        "StringLiteral",
	Template:             "Template",
}

type lexer struct {
	name          string     // used for error reports
	input         string     // the string being scanned
	start         int        // start position of this item
	pos           int        // current position of this input
	width         int        // width of last rune read
	tokens        chan Token // channel if scanned tokens
	reservedWords []string
	strict        bool
}

// func (l lexer) String() string {
// 	return fmt.Sprintf("name: \"%s\", start: %d, pos: %d, width: %d, input: \n------\n%s\n-----,",
// 		l.name, l.start, l.pos, l.width, l.input)
// }

// copied from: https://gobyexample.com/sorting-by-functions
type keywordSorter []string

func (s keywordSorter) Len() int {
	return len(s)
}
func (s keywordSorter) Swap(i, j int) {
	s[i], s[j] = s[j], s[i]
}
func (s keywordSorter) Less(i, j int) bool {
	return len(s[i]) > len(s[j]) // sorts reverse order
}

func (l *lexer) setStrict() {
	l.strict = true
	l.reservedWords = []string{}
	l.reservedWords = append(currentReservedWords, futureReservedWords...)
	l.reservedWords = append(currentReservedWords, literals...)
	l.reservedWords = append(l.reservedWords, futureResdervedWordsStrict...)
	sort.Sort(keywordSorter(l.reservedWords))
}

func (l *lexer) unsetStrict() {
	l.strict = false
	l.reservedWords = []string{}
	l.reservedWords = append(currentReservedWords, futureReservedWords...)
	l.reservedWords = append(currentReservedWords, literals...)
	sort.Sort(keywordSorter(l.reservedWords))
}

type stateFunc func(*lexer) stateFunc

func lex(name, input string, safe bool) (*lexer, chan Token) {
	l := &lexer{
		name:   name,
		input:  input,
		tokens: make(chan Token),
		strict: true,
	}
	if safe {
		l.setStrict()
	} else {
		l.unsetStrict()
	}

	go l.run()
	return l, l.tokens
}

// run lexes the input by executing state functions
// until the state is nil
func (l *lexer) run() {
	for state := lexInputElementDiv; state != nil; {
		state = state(l)
	}
	close(l.tokens)
}

func (l *lexer) emit(tok tokenType) {
	l.tokens <- Token{tok, l.input[l.start:l.pos], nil}
	l.start = l.pos
}

func (l *lexer) next() rune {
	var r rune
	if l.pos >= len(l.input) {
		l.width = 0
		return eof
	}
	r, l.width = utf8.DecodeRuneInString(l.input[l.pos:])
	l.pos += l.width
	return r
}

func (l *lexer) peek() rune {
	r := l.next()
	l.backup()
	return r
}

// ignore steps over the pending input before
// this point.
func (l *lexer) ignore() {
	l.start = l.pos
}

// backup steps back once per rune
// Can be called once per call of next
func (l *lexer) backup() {
	l.pos -= l.width
}

func (l *lexer) error(err error) stateFunc {
	l.tokens <- Token{Error, l.input[l.start:l.pos], err}
	return nil
}

func lexInputElementDiv(l *lexer) stateFunc {
	switch {
	case strings.HasPrefix(l.input[l.pos:], "//"): // SingleLineComment
		return lexSingleLineComment
	case strings.HasPrefix(l.input[l.pos:], "/*"): // MultiLineComment
		return lexMultiLineComment
	case hasWhiteSpacePrefix(l.input[l.pos:]):
		return lexWhiteSpace
	case hasLineTerminatorPrefix(l.input[l.pos:]):
		return lexLineTerminator
	case hasReservedWord(l, l.input[l.pos:]):
		return lexReservedWord(l)
	case hasPunctuator(l.input[l.pos:]):
		return lexPunctuator(l)
	case strings.HasPrefix(l.input[l.pos:], "/="): // DivPunctuator
		return lexDivPunctuator(l)
	case strings.HasPrefix(l.input[l.pos:], "/"): // DivPunctuator
		return lexDivPunctuator(l)
	case strings.HasPrefix(l.input[l.pos:], "}"): // RightBracePunctuator
		return lexRightBracePunctuator(l)
	case hasIdentifierNameStartPrefix(l): // IdentifierName
		return lexIdentifierName(l)
	case strings.HasPrefix(l.input[l.pos:], "\""): // StringLiteral
		return lexStringLiteralDouble(l)
	case strings.HasPrefix(l.input[l.pos:], "'"): // StringLiteral
		return lexStringLiteralSingle(l)
	default:
		return nil
	}
}

var punctuators = []string{"{", "(", ")", ">>>=", "<<=", "!==", "===", ">>>", "...", ">>=", ">=", "%=", "*=", "-=", "<=", "&=", "==", "!=", "|=", "^=", "+=", "<<", "||", "&&", "++", "--", "=>", ">>", "-", "&", "|", "^", "!", "~", "%", "*", "?", ":", "=", "+", ">", "<", ",", ";", ".", "]", "["}

func hasPunctuator(str string) bool {
	for _, punct := range punctuators {
		if strings.HasPrefix(str, punct) {
			return true
		}
	}
	return false
}

func lexPunctuator(l *lexer) stateFunc {
	for _, punct := range punctuators {
		if strings.HasPrefix(l.input[l.pos:], punct) {
			for i := len(punct); i > 0; i-- {
				l.next()
			}
			l.emit(Punctuator)
			return lexInputElementDiv
		}
	}
	return l.error(fmt.Errorf("punctuator word not found")) // Paranoic (should never happen)
}

func lexDivPunctuator(l *lexer) stateFunc {
	if strings.HasPrefix(l.input[l.pos:], "/=") {
		l.next()
		l.next()
		l.emit(DivPunctuator)
		return lexInputElementDiv
	}
	// if strings.HasPrefix(l.input[l.pos:], "/") {
	l.next()
	l.emit(DivPunctuator)
	return lexInputElementDiv
	// }
}

func lexRightBracePunctuator(l *lexer) stateFunc {
	// if strings.HasPrefix(l.input[l.pos:], "}") {
	l.next()
	l.emit(RightBracePunctuator)
	return lexInputElementDiv
	// }
	// return l.error(fmt.Errorf("div punctuator not found")) // Paranoic (should never happen)
}

var currentReservedWords = []string{
	"break", "do", "instanceof", "in", "typeof", "case", "else", "var", "catch", "export", "new", "void", "class", "extends", "return", "while", "const", "finally", "super", "with", "continue", "for", "switch", "yield", "debugger", "function", "this", "default", "if", "throw", "delete", "import", "try"}
var futureReservedWords = []string{"enum", "await"}
var futureResdervedWordsStrict = []string{"implements", "package", "protected", "interface", "private", "public"}
var literals = []string{"null", "true", "false"}

func hasReservedWord(l *lexer, str string) bool {
	for _, word := range l.reservedWords {
		if strings.HasPrefix(str, word) {
			return true
		}
	}
	return false
}

func lexReservedWord(l *lexer) stateFunc {
	for _, word := range l.reservedWords {
		if strings.HasPrefix(l.input[l.pos:], word) {
			for i := len(word); i > 0; i-- {
				l.next()
			}
			l.emit(ReservedWord)
			return lexInputElementDiv
		}
	}
	return l.error(fmt.Errorf("reserved word not found")) // Paranoic (should never happen)
}

func hasWhiteSpacePrefix(str string) bool {
	return strings.HasPrefix(str, string('\u0009')) || // WhiteSpace
		strings.HasPrefix(str, string('\u000B')) ||
		strings.HasPrefix(str, string('\u000C')) ||
		strings.HasPrefix(str, string('\u0020')) ||
		strings.HasPrefix(str, string('\u00A0')) ||
		strings.HasPrefix(str, string('\uFEFF')) ||
		strings.HasPrefix(str, string('\uFEFF'))
}

func lexWhiteSpace(l *lexer) stateFunc {
	for {
		if !hasWhiteSpacePrefix(l.input[l.pos:]) {
			break
		}
		l.next()
	}
	l.emit(WhiteSpace)
	return lexInputElementDiv
}

func hasLineTerminatorPrefix(str string) bool {
	return strings.HasPrefix(str, string('\u000A')) || // WhiteSpace
		strings.HasPrefix(str, string('\u000D')) ||
		strings.HasPrefix(str, string('\u2028')) ||
		strings.HasPrefix(str, string('\u2029'))
}

func lexLineTerminator(l *lexer) stateFunc {
	l.next()
	l.emit(LineTerminator)
	return lexInputElementDiv
}

func lexMultiLineComment(l *lexer) stateFunc {
	l.next() // /
	l.next() // *
	l.ignore()
	var r rune
	for {
		if strings.HasPrefix(l.input[l.pos:], "*/") {
			if l.pos > l.start {
				l.emit(MultiLineComment)
			}
			l.next() // *
			l.next() // /
			l.ignore()
			return lexInputElementDiv
		}
		if r = l.next(); r == eof {
			break
		}
	}
	return l.error(fmt.Errorf("no multi line comment terminator \"*/\""))
}

func lexSingleLineComment(l *lexer) stateFunc {
	l.start += 2
	for {
		if strings.HasPrefix(l.input[l.pos:], "\n") {
			if l.pos > l.start {
				l.emit(SingleLineComment)
				l.pos++
				return lexInputElementDiv
			}
		}
		if l.next() == eof {
			l.emit(SingleLineComment)
			return nil
		}
	}
}

func hasIdentifierNameStartPrefix(l *lexer) bool {
	r := l.peek()
	return r == '$' || r == '_' ||
		(unicode.IsOneOf([]*unicode.RangeTable{unicode.L, unicode.Nd, unicode.Other_ID_Start}, r) &&
			!(unicode.IsOneOf([]*unicode.RangeTable{unicode.Pattern_Syntax, unicode.Pattern_White_Space}, r)))
}

func hasIdentifierNameContinuePrefix(l *lexer) bool {
	r := l.peek()
	return hasIdentifierNameStartPrefix(l) || unicode.IsOneOf([]*unicode.RangeTable{unicode.L, unicode.Mn, unicode.Mc, unicode.Nd, unicode.Pc, unicode.Other_ID_Start}, r)
}

func lexIdentifierName(l *lexer) stateFunc {
	l.next()
	for {
		if !hasIdentifierNameContinuePrefix(l) {
			l.emit(IdentifierName)
			return lexInputElementDiv
		}
		l.next()
	}
}

func lexStringLiteralDouble(l *lexer) stateFunc {
	l.next()
	l.ignore()
	for {
		if strings.HasPrefix(l.input[l.pos:], "\"") {
			break
		}
		l.next()
	}
	l.emit(StringLiteral)
	l.ignore()
	return lexDivPunctuator
}
func lexStringLiteralSingle(l *lexer) stateFunc {
	l.next()
	l.ignore()
	for {
		if strings.HasPrefix(l.input[l.pos:], "\"") {
			break
		}
		l.next()
	}
	l.emit(StringLiteral)
	l.ignore()
	return lexDivPunctuator
}

// InputElementDiv ::
//  WhiteSpace
//  LineTerminator
//  Comment
//  CommonToken
//  DivPunctuator
//  RightBracePunctuator
// InputElementRegExp ::
//  WhiteSpace
//  LineTerminator
//  Comment
//  CommonToken
//  RightBracePunctuator
//  RegularExpressionLiteral
// InputElementRegExpOrTemplateTail ::
//  WhiteSpace
//  LineTerminator
//  Comment
//  CommonToken
//  RegularExpressionLiteral
//  TemplateSubstitutionTail
// InputElementTemplateTail ::
//  WhiteSpace
//  LineTerminator
//  Comment
//  CommonToken
//  DivPunctuator
//  TemplateSubstitutionTail
